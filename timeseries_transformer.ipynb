{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7852, 14) (10460, 14)\n"
     ]
    }
   ],
   "source": [
    "import wshrRelabelLight as WRL\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 指定文件夹路径\n",
    "# download_save_path = 'E:/Dataset/wind_shear/Data_Download'\n",
    "exception_save_path = '../Dataset/Exception_Data'\n",
    "\n",
    "# 获取文件夹下的所有文件名称\n",
    "# download_folder_names = [item for item in os.listdir(download_save_path) if os.path.isdir(os.path.join(download_save_path, item))]\n",
    "exception_folder_names = [item for item in os.listdir(exception_save_path) if os.path.isdir(os.path.join(exception_save_path, item))]\n",
    "instruction_folder_names = [\"@Instructions\"]\n",
    "\n",
    "# 生成所有文件夹路径\n",
    "# download_folder_paths = [os.path.join(download_save_path, item) for item in download_folder_names]\n",
    "exception_folder_paths = [os.path.join(exception_save_path, item) for item in exception_folder_names]\n",
    "\n",
    "# 指定读取变量名称\n",
    "'''\n",
    "CTSO仿真器输出变量：TIME, ALT, HDOT, VT, ALPHA, GAMMA, PITCH, GREF, WXDT, WZ, VDOT, ALRT\n",
    "没有WXDT和VDOT的原始数据，GREF不知道什么意思\n",
    "'''\n",
    "variable_list = ['ALT', 'ALTR', \"TAS\", 'GS', 'AOA1', 'AOA2', 'PTCH', 'WS', \"WD\", 'SAT', 'TAT', 'PI', 'PT']\n",
    "\n",
    "# 构建训练集和测试集\n",
    "train_folder_path = exception_folder_paths[3]\n",
    "train_mat_name = os.listdir(train_folder_path)[2]\n",
    "train_X, train_Y = WRL.dataConstruct(train_folder_path, train_mat_name, variable_list, normalized=False)\n",
    "\n",
    "test_folder_path = exception_folder_paths[1]\n",
    "test_mat_name = os.listdir(test_folder_path)[0]\n",
    "test_X, test_Y = WRL.dataConstruct(test_folder_path, test_mat_name, variable_list, normalized=False)\n",
    "\n",
    "train_wshr_warn_idx_list = np.where(train_Y[:, 0] == 0)[0]\n",
    "test_wshr_warn_idx_list = np.where(test_Y[:, 0] == 0)[0]\n",
    "\n",
    "# 计算飞行轨迹角\n",
    "variable_list.append('GAMMA')\n",
    "train_Gamma_X = train_X[:, 6] - np.mean(train_X[:, 4:5])\n",
    "test_Gamma_X = test_X[:, 6] - np.mean(test_X[:, 4:5])\n",
    "\n",
    "# 重组训练集和测试集数据\n",
    "train_X = np.hstack((train_X, train_Gamma_X.reshape(-1, 1)))\n",
    "test_X = np.hstack((test_X, test_Gamma_X.reshape(-1, 1)))\n",
    "\n",
    "# # 截取海拔位于50~2000英尺的起飞阶段数据\n",
    "# train_X = train_X[np.where((train_X[:int(train_X.shape[0]/2), 0] >= 50) & (train_X[:int(train_X.shape[0]/2), 0] <= 2000))[0]]\n",
    "# test_X = test_X[np.where((test_X[:int(test_X.shape[0]/2), 0] >= 50) & (test_X[:int(test_X.shape[0]/2), 0] <= 2000))[0]]\n",
    "# train_X = train_X[:5000, :]\n",
    "print(train_X.shape, test_X.shape)\n",
    "\n",
    "# 数据集归一化\n",
    "s_scaler = StandardScaler()\n",
    "train_X = s_scaler.fit_transform(train_X)\n",
    "train_mean, train_std = s_scaler.mean_, s_scaler.scale_\n",
    "test_X_origin = test_X\n",
    "test_X = s_scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([981, 8, 14])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "training mode is expected to be boolean",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 221\u001b[0m\n\u001b[0;32m    219\u001b[0m transformer \u001b[38;5;241m=\u001b[39m ForcastConvTransformer(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(variable_list), headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, seq_length\u001b[38;5;241m=\u001b[39mdecay_steps)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(train_batch_num):\n\u001b[1;32m--> 221\u001b[0m     \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_batch_X\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\coding\\Anaconda\\Software\\envs\\pytorch38\\lib\\site-packages\\torch\\nn\\modules\\module.py:2395\u001b[0m, in \u001b[0;36mModule.train\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m   2380\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sets the module in training mode.\u001b[39;00m\n\u001b[0;32m   2381\u001b[0m \n\u001b[0;32m   2382\u001b[0m \u001b[38;5;124;03mThis has any effect only on certain modules. See documentations of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2392\u001b[0m \u001b[38;5;124;03m    Module: self\u001b[39;00m\n\u001b[0;32m   2393\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mode, \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m-> 2395\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining mode is expected to be boolean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2396\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m   2397\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n",
      "\u001b[1;31mValueError\u001b[0m: training mode is expected to be boolean"
     ]
    }
   ],
   "source": [
    "# logSparse transformer 实现\n",
    "'''\n",
    "revised based on https://zhuanlan.zhihu.com/p/391337035\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "    device = 'cuda'\n",
    "\n",
    "# Self Attention Class\n",
    "class SelfAttentionConv(nn.Module):\n",
    "    def __init__(self, k, headers=8, kernel_size=5, mask_next=True, mask_diag=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.k, self.headers, self.kernel_size = k, headers, kernel_size # input_size, header_size, kernel_size\n",
    "        self.mask_next = mask_next\n",
    "        self.mask_diag = mask_diag\n",
    "\n",
    "        h = headers # 注意力头数\n",
    "\n",
    "        # Query, Key and Value Transformations\n",
    "        padding = (kernel_size - 1)\n",
    "        self.padding_opertor = nn.ConstantPad1d((padding, 0), 0)\n",
    "\n",
    "        self.toqueries = nn.Conv1d(k, k * h, kernel_size, padding=0, bias=True)\n",
    "        self.tokeys = nn.Conv1d(k, k * h, kernel_size, padding=0, bias=True)\n",
    "        self.tovalues = nn.Conv1d(k, k * h, kernel_size=1, padding=0, bias=False)  # No convolution operated\n",
    "        # kernel_size=1就是原始transformer，>1就是卷积transformer，卷积核能够收集到更多上下文趋势信息\n",
    "\n",
    "        # Heads unifier\n",
    "        self.unifyheads = nn.Linear(k * h, k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extraction dimensions\n",
    "        b, t, k = x.size()  # batch_size, number_of_timesteps, number_of_time_series\n",
    "\n",
    "        # Checking Embedding dimension\n",
    "        assert self.k == k, 'Number of time series ' + str(k) + ' didn t much the number of k ' + str(\n",
    "            self.k) + ' in the initiaalization of the attention layer.'\n",
    "        h = self.headers\n",
    "\n",
    "        #  Transpose to see the different time series as different channels\n",
    "        x = x.transpose(1, 2)\n",
    "        x_padded = self.padding_opertor(x)\n",
    "\n",
    "        # Query, Key and Value Transformations\n",
    "        queries = self.toqueries(x_padded).view(b, k, h, t)\n",
    "        keys = self.tokeys(x_padded).view(b, k, h, t)\n",
    "        values = self.tovalues(x).view(b, k, h, t)\n",
    "\n",
    "        # Transposition to return the canonical format\n",
    "        queries = queries.transpose(1, 2)  # batch, header, time serie, time step (b, h, k, t)\n",
    "        queries = queries.transpose(2, 3)  # batch, header, time step, time serie (b, h, t, k)\n",
    "\n",
    "        values = values.transpose(1, 2)  # batch, header, time serie, time step (b, h, k, t)\n",
    "        values = values.transpose(2, 3)  # batch, header, time step, time serie (b, h, t, k)\n",
    "\n",
    "        keys = keys.transpose(1, 2)  # batch, header, time serie, time step (b, h, k, t)\n",
    "        keys = keys.transpose(2, 3)  # batch, header, time step, time serie (b, h, t, k)\n",
    "\n",
    "        # Weights\n",
    "        queries = queries / (k ** (.25))\n",
    "        keys = keys / (k ** (.25))\n",
    "\n",
    "        queries = queries.transpose(1, 2).contiguous().view(b * h, t, k)\n",
    "        keys = keys.transpose(1, 2).contiguous().view(b * h, t, k)\n",
    "        values = values.transpose(1, 2).contiguous().view(b * h, t, k)\n",
    "\n",
    "        weights = torch.bmm(queries, keys.transpose(1, 2))\n",
    "\n",
    "        ## Mask the upper & diag of the attention matrix\n",
    "        if self.mask_next:\n",
    "            if self.mask_diag:\n",
    "                indices = torch.triu_indices(t, t, offset=0)\n",
    "                weights[:, indices[0], indices[1]] = float('-inf')\n",
    "            else:\n",
    "                indices = torch.triu_indices(t, t, offset=1)\n",
    "                weights[:, indices[0], indices[1]] = float('-inf')\n",
    "\n",
    "        # Softmax\n",
    "        weights = F.softmax(weights, dim=2)\n",
    "\n",
    "\n",
    "        # Output\n",
    "        output = torch.bmm(weights, values)\n",
    "        output = output.view(b, h, t, k)\n",
    "        output = output.transpose(1, 2).contiguous().view(b, t, k * h)\n",
    "\n",
    "        return self.unifyheads(output)  # shape (b,t,k)\n",
    "\n",
    "# Conv Transforme Block\n",
    "class ConvTransformerBLock(nn.Module):\n",
    "    def __init__(self, k, headers, kernel_size=5, mask_next=True, mask_diag=False, dropout_proba=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        # Self attention\n",
    "        self.attention = SelfAttentionConv(k, headers, kernel_size, mask_next, mask_diag)\n",
    "\n",
    "        # First & Second Norm\n",
    "        self.norm1 = nn.LayerNorm(k)\n",
    "        self.norm2 = nn.LayerNorm(k)\n",
    "\n",
    "        # Feed Forward Network\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(k, 4 * k),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * k, k)\n",
    "        )\n",
    "\n",
    "        # Dropout funtcion  & Relu:\n",
    "        self.dropout = nn.Dropout(p=dropout_proba)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, train=False):\n",
    "        # Self attention + Residual\n",
    "        x = self.attention(x) + x\n",
    "\n",
    "        # Dropout attention\n",
    "        if train:\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        # First Normalization\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        # Feed Froward network + residual\n",
    "        x = self.feedforward(x) + x\n",
    "\n",
    "        # Second Normalization\n",
    "        x = self.norm2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Forcasting Conv Transformer :\n",
    "class ForcastConvTransformer(nn.Module):\n",
    "    def __init__(self, k, headers, depth, seq_length, kernel_size=5, mask_next=True, mask_diag=False, dropout_proba=0.2,\n",
    "                 num_tokens=None):\n",
    "        super().__init__()\n",
    "        # Embedding\n",
    "        self.tokens_in_count = False\n",
    "        if num_tokens:\n",
    "            self.tokens_in_count = True\n",
    "            self.token_embedding = nn.Embedding(num_tokens, k)  # （369, 1）= (nb_ts, k)\n",
    "\n",
    "        # Embedding the position\n",
    "        self.position_embedding = nn.Embedding(seq_length, k)   # (500, 1) = (windows_size, k)\n",
    "\n",
    "        # Number of kind of time series\n",
    "        self.k = k  # 没有协变量的情况下，k=1\n",
    "        self.seq_length = seq_length    # seq_length即窗口大小, 数据准备的时候切割好了\n",
    "\n",
    "        # Transformer blocks\n",
    "        tblocks = []\n",
    "        # log sparse 稀疏策略： 采用多层ConvTrans层堆叠的方式\n",
    "        for t in range(depth):\n",
    "            tblocks.append(ConvTransformerBLock(k, headers, kernel_size, mask_next, mask_diag, dropout_proba))\n",
    "        self.TransformerBlocks = nn.Sequential(*tblocks)\n",
    "\n",
    "        # Transformation from k dimension to numClasses\n",
    "        self.topreSigma = nn.Linear(k, 1)\n",
    "        self.tomu = nn.Linear(k, 1)\n",
    "        self.plus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x, tokens=None):\n",
    "        b, t, k = x.size()\n",
    "\n",
    "        # checking that the given batch had same number of time series as the BLock had\n",
    "        assert k == self.k, 'The k :' + str(\n",
    "            self.k) + ' number of timeseries given in the initialization is different than what given in the x :' + str(\n",
    "            k)\n",
    "        assert t == self.seq_length, 'The lenght of the timeseries given t ' + str(\n",
    "            t) + ' miss much with the lenght sequence given in the Tranformers initialisation self.seq_length: ' + str(\n",
    "            self.seq_length)\n",
    "\n",
    "        # Position embedding\n",
    "        pos = torch.arange(t)\n",
    "        self.pos_emb = self.position_embedding(pos).expand(b, t, k)\n",
    "\n",
    "        # Checking token embedding\n",
    "        assert self.tokens_in_count == (not (tokens is None)), 'self.tokens_in_count = ' + str(\n",
    "            self.tokens_in_count) + ' should be equal to (not (tokens is None)) = ' + str((not (tokens is None)))\n",
    "        if not (tokens is None):\n",
    "            ## checking that the number of tockens corresponde to the number of batch elements\n",
    "            assert tokens.size(0) == b\n",
    "            self.tok_emb = self.token_embedding(tokens)\n",
    "            self.tok_emb = self.tok_emb.expand(t, b, k).transpose(0, 1)\n",
    "\n",
    "        # Adding Pos Embedding and token Embedding to the variable\n",
    "        if not (tokens is None):\n",
    "            x = self.pos_emb + self.tok_emb + x\n",
    "        else:\n",
    "            x = self.pos_emb + x\n",
    "\n",
    "        # Transformer :\n",
    "        x = self.TransformerBlocks(x)\n",
    "        mu = self.tomu(x)\n",
    "        presigma = self.topreSigma(x)\n",
    "        sigma = self.plus(presigma)\n",
    "\n",
    "        return mu, sigma\n",
    "\n",
    "# 将训练集整理为shape = [batch_size, number_of_timesteps, number_of_time_series]的形式\n",
    "decay_steps = 8\n",
    "batch_size = 256\n",
    "train_batch_num = train_X.shape[0] // decay_steps\n",
    "train_batch_X = np.array([train_X[i * decay_steps: (i + 1) * decay_steps, :] for i in range(train_batch_num)])\n",
    "\n",
    "# 转化为tensor并放到对应设备上\n",
    "train_batch_X = torch.from_numpy(train_batch_X).float().to(device)\n",
    "\n",
    "print(train_batch_X.size())\n",
    "\n",
    "# 构建transformer模型\n",
    "transformer = ForcastConvTransformer(k=len(variable_list), headers=8, depth=4, seq_length=decay_steps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\coding\\Anaconda\\Software\\envs\\pytorch38\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning:\n",
      "\n",
      "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "\n",
      "d:\\coding\\Anaconda\\Software\\envs\\pytorch38\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning:\n",
      "\n",
      "Using a target size (torch.Size([100, 1, 1])) that is different to the input size (torch.Size([100, 10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.1417\n",
      "Epoch [2/10], Loss: 1.0456\n",
      "Epoch [3/10], Loss: 0.1891\n",
      "Epoch [4/10], Loss: 0.2402\n",
      "Epoch [5/10], Loss: 0.4332\n",
      "Epoch [6/10], Loss: 0.3292\n",
      "Epoch [7/10], Loss: 0.1805\n",
      "Epoch [8/10], Loss: 0.1079\n",
      "Epoch [9/10], Loss: 0.1526\n",
      "Epoch [10/10], Loss: 0.2091\n",
      "True Output tensor([[[0.2959],\n",
      "         [0.9293],\n",
      "         [0.2659],\n",
      "         [0.8281],\n",
      "         [0.9851],\n",
      "         [0.7834],\n",
      "         [0.5190],\n",
      "         [0.0661],\n",
      "         [0.4724],\n",
      "         [0.4383]]])\n",
      "Predicted Output: tensor([[[ 0.4032],\n",
      "         [ 0.2537],\n",
      "         [ 0.1978],\n",
      "         [-0.1069],\n",
      "         [ 0.1016],\n",
      "         [ 0.0019],\n",
      "         [ 0.4538],\n",
      "         [ 0.2146],\n",
      "         [ 0.1194],\n",
      "         [ 0.1969]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# 构建Transformer模型\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, seq_len, num_layers, d_model, num_heads, d_ff, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Linear(input_dim, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout, seq_len)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model, num_heads, d_ff, dropout),\n",
    "            num_layers\n",
    "        )\n",
    "        self.decoder = nn.Linear(d_model, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # 输入数据经过线性变换\n",
    "        x = self.positional_encoding(x)  # 加入位置编码\n",
    "        x = self.transformer_encoder(x)  # Transformer编码器\n",
    "        x = self.decoder(x)  # 解码成目标维度\n",
    "        return x\n",
    "\n",
    "# 位置编码\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# 构建训练和测试数据\n",
    "input_dim = 1  # 输入维度\n",
    "output_dim = 1  # 输出维度\n",
    "seq_len = 10  # 时间序列长度\n",
    "num_layers = 4  # Transformer层数\n",
    "d_model = 64  # 模型维度\n",
    "num_heads = 4  # 注意力头数\n",
    "d_ff = 128  # 前馈神经网络的隐藏层维度\n",
    "dropout = 0.1  # Dropout概率\n",
    "\n",
    "# 构建随机时间序列数据\n",
    "np.random.seed(0)\n",
    "x_train = np.random.rand(100, seq_len, input_dim).astype(np.float32)\n",
    "y_train = np.random.rand(100, 1, output_dim).astype(np.float32)\n",
    "\n",
    "# 转换为Tensor\n",
    "x_train_tensor = torch.from_numpy(x_train).to(device)\n",
    "y_train_tensor = torch.from_numpy(y_train).to(device)\n",
    "\n",
    "# 初始化Transformer模型\n",
    "model = TransformerModel(input_dim, output_dim, seq_len, num_layers, d_model, num_heads, d_ff, dropout)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x_train_tensor)\n",
    "    loss = criterion(output, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, loss.item()))\n",
    "\n",
    "# 使用模型进行预测\n",
    "test_input = torch.from_numpy(np.random.rand(1, seq_len, input_dim).astype(np.float32)).to(device)\n",
    "predicted_output = model(test_input)\n",
    "print('True Output', test_input)\n",
    "print('Predicted Output:', predicted_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
