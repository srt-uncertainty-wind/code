{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import random\n",
    "\n",
    "# 指定文件夹路径\n",
    "download_save_path = 'E:/Dataset/wind_shear/Data_Download'\n",
    "exception_save_path = '../Dataset/Exception_Data'\n",
    "\n",
    "# 获取文件夹下的所有文件名称\n",
    "download_folder_names = [item for item in os.listdir(download_save_path) if os.path.isdir(os.path.join(download_save_path, item))]\n",
    "exception_folder_names = [item for item in os.listdir(exception_save_path) if os.path.isdir(os.path.join(exception_save_path, item))]\n",
    "instruction_folder_names = [\"@Instructions\"]\n",
    "\n",
    "# 生成所有文件夹路径\n",
    "download_folder_paths = [os.path.join(download_save_path, item) for item in download_folder_names]\n",
    "exception_folder_paths = [os.path.join(exception_save_path, item) for item in exception_folder_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mechanism: 38\n",
      "power: 47\n",
      "control: 37\n",
      "external: 15\n",
      "recorder: 7\n",
      "unclassified: 19\n",
      "\n",
      "163 variables in total\n"
     ]
    }
   ],
   "source": [
    "# give the preset classification of variables\n",
    "group_names_list = [\"mechanism\", \"power\", \"control\", \"external\", \"recorder\", \"unclassified\"]\n",
    "group_lens_dict = {}\n",
    "\n",
    "var_group_mechanism = [\"AIL_1\", \"AIL_2\", \"FLAP\", \"ELEV_1\", \"ELEV_2\", \"RUDD\", \"SPL_1\", \"SPL_2\", \"SPLG\", \"SPLY\", \"ABRK\", \"BPGR_1\", \"BPGR_2\", \"BPYR_1\", \"BPYR_2\", \"MSQT_1\", \"MSQT_2\", \"NSQT\", \"BLV\", \"CALT\", \"PACK\", \"WOW\", \n",
    "                       \"AOA1\", \"AOA2\", \"GLS\", \"PTCH\", \"ROLL\", \n",
    "                       \"TH\", \"MH\", \"TAS\", \"CASM\", \"GS\", \"IVV\",\n",
    "                       \"VRTG\", \"LATG\", \"LONG\", \"FPAC\", \"CTAC\"]\n",
    "var_group_power = [\"N2_1\", \"N2_2\", \"N2_3\", \"N2_4\",\n",
    "                   \"ECYC_1\", \"ECYC_2\", \"ECYC_3\", \"ECYC_4\", \"EHRS_1\", \"EHRS_2\", \"EHRS_3\", \"EHRS_4\", \"VIB_1\", \"VIB_2\", \"VIB_3\", \"VIB_4\", \"FADS\", \"HYDG\", \"HYDY\",\n",
    "                   \"N1_1\", \"N1_2\", \"N1_3\", \"N1_4\", \"N1T\", \"FF_1\", \"FF_2\", \"FF_3\", \"FF_4\", \"FQTY_1\", \"FQTY_2\", \"FQTY_3\", \"FQTY_4\", \"OIP_1\", \"OIP_2\", \"OIP_3\", \"OIP_4\", \"OIT_1\", \"OIT_2\", \"OIT_3\", \"OIT_4\", \"OIPL\", \"EGT_1\", \"EGT_2\", \"EGT_3\", \"EGT_4\",\n",
    "                   \"LGDN\", \"LGUP\"]\n",
    "var_group_control = [\"CRSS\", \"HDGS\", \"A_T\", \"APFD\", \"DFGS\", \"FGC3\", \"PUSH\", \"PTRM\", \"TCAS\",\n",
    "                     \"ILSF\", \"RUDP\", \"CCPC\", \"CCPF\", \"CWPC\", \"CWPF\", \"PLA_1\", \"PLA_2\", \"PLA_3\", \"PLA_4\",\n",
    "                     \"SNAP\", \"TMODE\", \"EAI\", \"TAI\", \"WAI_1\", \"WAI_2\", \n",
    "                     \"APUF\", \"FADF\", \"FIRE_1\", \"FIRE_2\", \"FIRE_3\", \"FIRE_4\", \"GPWS\", \"MW\", \"POVT\", \"SHKR\", \"SMOK\", \"TOCW\"]\n",
    "var_group_external = [\"ALT\", \"ALTR\", \"WS\", \"WD\", \"PI\", \"PS\", \"PT\", \"SAT\", \"TAT\",\n",
    "                      \"DA\", \"TRK\", \"TRKM\", \"LOC\", \"LATP\", \"LONP\"]\n",
    "var_group_recorder = [\"DWPT\", \"PH\", \n",
    "                     \"ACMT\", \"FRMC\", \"GMT_HOUR\", \"GMT_MINUTE\", \"GMT_SEC\"]\n",
    "var_group_unclassified = [\"ATEN\", \"EVNT\", \"HF1\", \"HF2\", \"VHF1\", \"VHF2\", \"VHF3\", \"LMOD\", \"VMODE\", \"MACH\", \"MNS\", \"MRK\", \"N1C\", \"N1CO\", \"SMKB\", \"VAR_1107\", \"VAR_2670\", \"VAR_5107\", \"VAR_6670\"]\n",
    "\n",
    "var_groups_dict = {\"mechanism\": var_group_mechanism, \"power\": var_group_power, \"control\": var_group_control, \"external\": var_group_external, \"recorder\": var_group_recorder, \"unclassified\": var_group_unclassified}\n",
    "for group_name, var_group in var_groups_dict.items():\n",
    "    group_lens_dict[group_name] = len(var_group)\n",
    "    print(f\"{group_name}: {len(var_group)}\")\n",
    "print(f\"\\n{sum(group_lens_dict.values())} variables in total\")\n",
    "\n",
    "# 查找给定总序数对应的变量名称\n",
    "def find_var_name(idx, var_dict):\n",
    "    count = 0\n",
    "    group_lens_dict = {}\n",
    "    for group_name, var_group in var_dict.items():\n",
    "        group_lens_dict[group_name] = len(var_group)\n",
    "    for group_name, var_group in var_dict.items():\n",
    "        if count + group_lens_dict[group_name] > idx:\n",
    "            return group_name, var_group[idx - count]\n",
    "        else:\n",
    "            count += group_lens_dict[group_name]\n",
    "\n",
    "# 查找给定变量名称对应的总序数\n",
    "def find_var_idx(var_name, var_dict):\n",
    "    count = 0\n",
    "    for var_list in var_dict.values():\n",
    "        if var_name in var_list:\n",
    "            count += var_list.index(var_name)\n",
    "            return(count)\n",
    "        else:\n",
    "            count += len(var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行pca分析\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 设置工作目录\n",
    "download_folder_name = 'Tail_652_1'\n",
    "\n",
    "# 设置结果存储目录\n",
    "pca_save_path = '../result/variable_evaluate/pca'\n",
    "if not os.path.exists(pca_save_path):\n",
    "    os.mkdir(pca_save_path)\n",
    "\n",
    "# 初始化pca结果存储array\n",
    "ev_ratio_array = []\n",
    "PCs_array = []\n",
    "\n",
    "for mat_name in os.listdir(os.path.join(download_save_path, download_folder_name)):\n",
    "    # 载入mat文件\n",
    "    mat = loadmat(os.path.join(download_save_path, download_folder_name, mat_name))\n",
    "    # 将mat文件整理成(163, )的array\n",
    "    wshr_data = mat[\"WSHR\"][0][0][0]\n",
    "    sampling_data_array = []\n",
    "    for var_list in var_groups_dict.values():\n",
    "        for var_name in var_list:\n",
    "            var_data, var_rate = mat[var_name][0][0][0], mat[var_name][0][0][1][0][0]\n",
    "            # 对每个变量按照rate进行下采样或过采样，对长为n+1的数据，抓取前n个全变量为输入，后n个有缺变量为输出\n",
    "            if var_rate == 1:\n",
    "                sampling_data = var_data\n",
    "            elif var_rate > 1: # 进行下采样\n",
    "                sampling_data = random.sample(var_data.tolist(), k=len(wshr_data))\n",
    "            else:\n",
    "                sampling_data = random.choices(var_data, k=len(wshr_data))\n",
    "            sampling_data_array.append(sampling_data)\n",
    "    summary_data_array = np.squeeze(np.array(sampling_data_array)).T\n",
    "    # print(summary_data_array.shape)\n",
    "\n",
    "    # 创建一个PCA对象并指定要保留的主成分数量\n",
    "    # n_components = summary_data_array.shape[0]\n",
    "    n_components = 50\n",
    "    pca = PCA(n_components)\n",
    "\n",
    "    # 对数据集进行PCA\n",
    "    pca.fit_transform(summary_data_array)\n",
    "\n",
    "    # 获取主成分的方差解释比例\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    ev_ratio_array.append(explained_variance_ratio)\n",
    "    # print(\"解释方差比例：\", explained_variance_ratio, \"  ----- 总计：\", sum(explained_variance_ratio))\n",
    "\n",
    "    # 获取主成分的特征向量\n",
    "    components = pca.components_\n",
    "    PCs_array.append(components)\n",
    "    # print(\"主成分特征向量：\", components)\n",
    "\n",
    "    # break\n",
    "\n",
    "ev_ratio_array = np.array(ev_ratio_array)\n",
    "PCs_array = np.array(PCs_array)\n",
    "\n",
    "# 存储结果array\n",
    "# np.save(os.path.join(pca_save_path, \"ev_ratio_array.npy\"), ev_ratio_array)\n",
    "# np.save(os.path.join(pca_save_path, \"PCs_array.npy\"), PCs_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(676, 50)\n",
      "(676, 50, 163)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(ev_ratio_array).shape)\n",
    "print(np.array(PCs_array).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 13, 22, 23, 74, 77, 81, 82, 92, 95, 96, 97, 98, 119, 122, 123, 127, 128, 139, 140]\n",
      "156\n"
     ]
    }
   ],
   "source": [
    "# 筛选关键变量的最小交集和最大并集\n",
    "\n",
    "# 规定主成分方差解释比例阈值，以及变量解释阈值的最小绝对值\n",
    "PC_threshold = 0.95\n",
    "var_abs_threshold = 0.00\n",
    "\n",
    "# 计算每个mat要保留的主成分数量\n",
    "PC_num_list = []\n",
    "for ev_ratio_list in ev_ratio_array:\n",
    "    sum_ev_ratio = 0\n",
    "    for i, ev_ratio in enumerate(ev_ratio_list):\n",
    "        sum_ev_ratio += ev_ratio\n",
    "        if sum_ev_ratio >= PC_threshold:\n",
    "            PC_num_list.append(i+1)\n",
    "            break\n",
    "\n",
    "# 初始化变量存在性array和加权存在性矩阵\n",
    "var_exist_array = np.zeros((len(PC_num_list), 163))\n",
    "var_weighted_exist_array = np.zeros((len(PC_num_list), 163))\n",
    "\n",
    "# 更新每个mat中主成分中存在的变量\n",
    "for i, PC_array in enumerate(PCs_array):\n",
    "    # threshold_PC_array = PC_array[:PC_num_list[i]]\n",
    "    for k, PC in enumerate(PC_array[:PC_num_list[i]]):\n",
    "        exist_idx = np.where(abs(PC) > var_abs_threshold)[0]\n",
    "        var_exist_array[i][exist_idx] = 1\n",
    "        var_weighted_exist_array[i][exist_idx] += ev_ratio_array[i][k] * PC[exist_idx]\n",
    "\n",
    "# 存储变量存在性和加权存在性array\n",
    "np.save(os.path.join(pca_save_path, \"var_exist_array.npy\"), var_exist_array)\n",
    "np.save(os.path.join(pca_save_path, \"var_weighted_exist_array.npy\"), var_weighted_exist_array)\n",
    "\n",
    "# 查找array中的全1列序数作为关键变量的最小交\n",
    "all_ones_cols_list = []\n",
    "for i in range(var_exist_array.shape[1]):\n",
    "    if all(element == 1 for element in var_exist_array[:, i]):\n",
    "        all_ones_cols_list.append(i)\n",
    "print(all_ones_cols_list) # 0.001没有，0有\n",
    "'''\n",
    "('mechanism', 'AIL_1', 'AIL_2', 'FLAP', 'ELEV_1', 'ELEV_2', 'RUDD', 'SPL_1', 'SPL_2', 'BPYR_1', 'AOA1', 'AOA2')\n",
    "('power', 'OIT_1', 'OIT_4', 'EGT_3', 'EGT_4')\n",
    "('control', 'PTRM', 'RUDP', 'CCPC', 'CCPF', 'CWPC', 'SHKR')\n",
    "('external', 'ALT', 'ALTR', 'PS', 'PT')\n",
    "('recorder', 'ACMT', 'FRMC')\n",
    "'''\n",
    "\n",
    "# 查找array中的非全0列序数作为关键变量的最大并\n",
    "non_zeros_cols_list = []\n",
    "for i in range(var_exist_array.shape[1]):\n",
    "    if any(element == 1 for element in var_exist_array[:, i]):\n",
    "        non_zeros_cols_list.append(i)\n",
    "print(len(non_zeros_cols_list)) # 54个\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mechanism', 'AIL_1')\n",
      "('mechanism', 'AIL_2')\n",
      "('mechanism', 'FLAP')\n",
      "('mechanism', 'ELEV_1')\n",
      "('mechanism', 'ELEV_2')\n",
      "('mechanism', 'RUDD')\n",
      "('mechanism', 'SPL_1')\n",
      "('mechanism', 'SPL_2')\n",
      "('mechanism', 'BPYR_1')\n",
      "('mechanism', 'AOA1')\n",
      "('mechanism', 'AOA2')\n",
      "('power', 'OIT_1')\n",
      "('power', 'OIT_4')\n",
      "('power', 'EGT_3')\n",
      "('power', 'EGT_4')\n",
      "('control', 'PTRM')\n",
      "('control', 'RUDP')\n",
      "('control', 'CCPC')\n",
      "('control', 'CCPF')\n",
      "('control', 'CWPC')\n",
      "('control', 'SHKR')\n",
      "('external', 'ALT')\n",
      "('external', 'ALTR')\n",
      "('external', 'PS')\n",
      "('external', 'PT')\n",
      "('recorder', 'ACMT')\n",
      "('recorder', 'FRMC')\n"
     ]
    }
   ],
   "source": [
    "for idx in all_ones_cols_list:\n",
    "    print(find_var_name(idx, var_groups_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
