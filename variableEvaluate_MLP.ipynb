{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 指定文件夹路径\n",
    "download_save_path = 'E:/Dataset/wind_shear/Data_Download'\n",
    "exception_save_path = '../Dataset/Exception_Data'\n",
    "plt_save_path = '../result/WSHR/figures'\n",
    "\n",
    "# 获取文件夹下的所有文件名称\n",
    "download_folder_names = [item for item in os.listdir(download_save_path) if os.path.isdir(os.path.join(download_save_path, item))]\n",
    "exception_folder_names = [item for item in os.listdir(exception_save_path) if os.path.isdir(os.path.join(exception_save_path, item))]\n",
    "instruction_folder_names = [\"@Instructions\"]\n",
    "\n",
    "# 生成所有文件夹路径\n",
    "download_folder_paths = [os.path.join(download_save_path, item) for item in download_folder_names]\n",
    "exception_folder_paths = [os.path.join(exception_save_path, item) for item in exception_folder_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mechanism: 25\n",
      "power: 11\n",
      "control: 11\n",
      "external: 6\n",
      "recorder: 1\n",
      "unclassified: 7\n",
      "\n",
      "61 variables in total\n"
     ]
    }
   ],
   "source": [
    "# give the preset classification of determined variables\n",
    "group_names_list = [\"mechanism\", \"power\", \"control\", \"external\", \"recorder\", \"unclassified\"]\n",
    "group_lens_dict = {}\n",
    "\n",
    "var_group_mechanism = [\"AIL_1\", \"AIL_2\", \"FLAP\", \"ELEV_1\", \"ELEV_2\", \"RUDD\", \"SPL_1\", \"SPL_2\", \"SPLG\", \"ABRK\", \"NSQT\",\n",
    "                       \"AOA1\", \"AOA2\", \"GLS\", \"PTCH\", \"ROLL\", \"TH\", \n",
    "                       \"TAS\", \"CASM\", \"GS\",\n",
    "                       \"VRTG\", \"LATG\", \"LONG\", \"FPAC\", \"CTAC\"]\n",
    "var_group_power = [\n",
    "                   \"FADS\", \n",
    "                   \n",
    "                   \"FQTY_1\", \"FQTY_2\", \"FQTY_3\", \"FQTY_4\", \"OIT_1\", \"OIT_2\", \"OIT_3\", \"OIT_4\", \"OIPL\",\n",
    "                   \"LGDN\"]\n",
    "var_group_control = [\"HDGS\", \"PTRM\", \n",
    "                     \"RUDP\", \"CCPC\", \"CCPF\", \"CWPC\", \"CWPF\",\n",
    "                     \"SNAP\", \n",
    "                     \"GPWS\", \"SHKR\", \"FADF\"]\n",
    "var_group_external = [\"ALT\", \"WS\", \"WD\", \"PT\", \"TAT\",\n",
    "                      \"LOC\"]\n",
    "var_group_recorder = [\"PH\"\n",
    "                     ]\n",
    "var_group_unclassified = [\"EVNT\", \"HF1\", \"HF2\", \"VHF1\", \"VHF2\", \"VHF3\", \"SMKB\"]\n",
    "\n",
    "var_groups_dict = {\"mechanism\": var_group_mechanism, \"power\": var_group_power, \"control\": var_group_control, \"external\": var_group_external, \"recorder\": var_group_recorder, \"unclassified\": var_group_unclassified}\n",
    "for group_name, var_group in var_groups_dict.items():\n",
    "    group_lens_dict[group_name] = len(var_group)\n",
    "    print(f\"{group_name}: {len(var_group)}\")\n",
    "print(f\"\\n{sum(group_lens_dict.values())} variables in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receive mat 653200212291431.mat\n",
      "Receive mat 660200210081101.mat\n",
      "Receive mat 686200105101854.mat\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "检查所有预选变量在原始数据中的完整性，筛选出能保证全变量完整的子数据集作为MLP的训练集和测试集；\n",
    "以训练的MLP对原始数据进行数据补正，以供之后通过随机森林在WSHR的二分类问题上对特征变量进行再次评估，以迭代出新的预选变量集\n",
    "'''\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# 检查预选变量数据完整性并生成工作子集\n",
    "def check_var_integrity(mat, mat_name):\n",
    "    for group_name, var_group in var_groups_dict.items():\n",
    "        for var_name in var_group:\n",
    "            if np.mean(mat[var_name][0][0][0]) == 0 and np.var(mat[var_name][0][0][0]) == 0:\n",
    "                # print(f\"{var_name} in {group_name} is empty\")\n",
    "                # print(f\"Jump mat {mat_name}\")\n",
    "                return False\n",
    "    print(f\"Receive mat {mat_name}\")\n",
    "    return True\n",
    "\n",
    "work_dict = {}\n",
    "# for exception_folder_path in exception_folder_paths:\n",
    "#     for exception_mat_name in os.listdir(exception_folder_path):\n",
    "#         e_mat = loadmat(os.path.join(exception_folder_path, exception_mat_name))\n",
    "#         if check_var_integrity(e_mat, exception_mat_name):\n",
    "#             work_dict[exception_mat_name] = e_mat\n",
    "'''\n",
    "Received matname: ['653200212291431.mat', '660200210081101.mat','686200105101854.mat']\n",
    "'''\n",
    "\n",
    "for download_folder_path in download_folder_paths:\n",
    "    for download_mat_name in os.listdir(download_folder_path):\n",
    "        d_mat = loadmat(os.path.join(download_folder_path, download_mat_name))\n",
    "        if check_var_integrity(d_mat, download_mat_name):\n",
    "            work_dict[download_mat_name] = d_mat\n",
    "'''\n",
    "Received matname: ['653200212291431.mat', '660200210081101.mat','686200105101854.mat']\n",
    "'''\n",
    "\n",
    "np.save(\"../result/variable_evaluate/work_dict.npy\", work_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
