{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import random\n",
    "\n",
    "# 指定文件夹路径\n",
    "download_save_path = 'E:/Dataset/wind_shear/Data_Download'\n",
    "exception_save_path = '../Dataset/Exception_Data'\n",
    "cluster_save_path = '../result/variable_cluster/rough&smooth'\n",
    "\n",
    "# 获取文件夹下的所有文件名称\n",
    "download_folder_names = [item for item in os.listdir(download_save_path) if os.path.isdir(os.path.join(download_save_path, item))]\n",
    "exception_folder_names = [item for item in os.listdir(exception_save_path) if os.path.isdir(os.path.join(exception_save_path, item))]\n",
    "instruction_folder_names = [\"@Instructions\"]\n",
    "\n",
    "# 生成所有文件夹路径\n",
    "download_folder_paths = [os.path.join(download_save_path, item) for item in download_folder_names]\n",
    "exception_folder_paths = [os.path.join(exception_save_path, item) for item in exception_folder_names]\n",
    "\n",
    "# 指定工作文件夹\n",
    "work_folder_path = exception_folder_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mechanism: 38\n",
      "power: 47\n",
      "control: 37\n",
      "external: 15\n",
      "recorder: 7\n",
      "unclassified: 19\n",
      "\n",
      "163 variables in total\n"
     ]
    }
   ],
   "source": [
    "# give the preset classification of variables\n",
    "group_names_list = [\"mechanism\", \"power\", \"control\", \"external\", \"recorder\", \"unclassified\"]\n",
    "group_lens_dict = {}\n",
    "\n",
    "var_group_mechanism = [\"AIL_1\", \"AIL_2\", \"FLAP\", \"ELEV_1\", \"ELEV_2\", \"RUDD\", \"SPL_1\", \"SPL_2\", \"SPLG\", \"SPLY\", \"ABRK\", \"BPGR_1\", \"BPGR_2\", \"BPYR_1\", \"BPYR_2\", \"MSQT_1\", \"MSQT_2\", \"NSQT\", \"BLV\", \"CALT\", \"PACK\", \"WOW\", \n",
    "                       \"AOA1\", \"AOA2\", \"GLS\", \"PTCH\", \"ROLL\", \n",
    "                       \"TH\", \"MH\", \"TAS\", \"CASM\", \"GS\", \"IVV\",\n",
    "                       \"VRTG\", \"LATG\", \"LONG\", \"FPAC\", \"CTAC\"]\n",
    "var_group_power = [\"N2_1\", \"N2_2\", \"N2_3\", \"N2_4\",\n",
    "                   \"ECYC_1\", \"ECYC_2\", \"ECYC_3\", \"ECYC_4\", \"EHRS_1\", \"EHRS_2\", \"EHRS_3\", \"EHRS_4\", \"VIB_1\", \"VIB_2\", \"VIB_3\", \"VIB_4\", \"FADS\", \"HYDG\", \"HYDY\",\n",
    "                   \"N1_1\", \"N1_2\", \"N1_3\", \"N1_4\", \"N1T\", \"FF_1\", \"FF_2\", \"FF_3\", \"FF_4\", \"FQTY_1\", \"FQTY_2\", \"FQTY_3\", \"FQTY_4\", \"OIP_1\", \"OIP_2\", \"OIP_3\", \"OIP_4\", \"OIT_1\", \"OIT_2\", \"OIT_3\", \"OIT_4\", \"OIPL\", \"EGT_1\", \"EGT_2\", \"EGT_3\", \"EGT_4\",\n",
    "                   \"LGDN\", \"LGUP\"]\n",
    "var_group_control = [\"CRSS\", \"HDGS\", \"A_T\", \"APFD\", \"DFGS\", \"FGC3\", \"PUSH\", \"PTRM\", \"TCAS\",\n",
    "                     \"ILSF\", \"RUDP\", \"CCPC\", \"CCPF\", \"CWPC\", \"CWPF\", \"PLA_1\", \"PLA_2\", \"PLA_3\", \"PLA_4\",\n",
    "                     \"SNAP\", \"TMODE\", \"EAI\", \"TAI\", \"WAI_1\", \"WAI_2\", \n",
    "                     \"APUF\", \"FADF\", \"FIRE_1\", \"FIRE_2\", \"FIRE_3\", \"FIRE_4\", \"GPWS\", \"MW\", \"POVT\", \"SHKR\", \"SMOK\", \"TOCW\"]\n",
    "var_group_external = [\"ALT\", \"ALTR\", \"WS\", \"WD\", \"PI\", \"PS\", \"PT\", \"SAT\", \"TAT\",\n",
    "                      \"DA\", \"TRK\", \"TRKM\", \"LOC\", \"LATP\", \"LONP\"]\n",
    "var_group_recorder = [\"DWPT\", \"PH\", \n",
    "                     \"ACMT\", \"FRMC\", \"GMT_HOUR\", \"GMT_MINUTE\", \"GMT_SEC\"]\n",
    "var_group_unclassified = [\"ATEN\", \"EVNT\", \"HF1\", \"HF2\", \"VHF1\", \"VHF2\", \"VHF3\", \"LMOD\", \"VMODE\", \"MACH\", \"MNS\", \"MRK\", \"N1C\", \"N1CO\", \"SMKB\", \"VAR_1107\", \"VAR_2670\", \"VAR_5107\", \"VAR_6670\"]\n",
    "\n",
    "var_groups_dict = {\"mechanism\": var_group_mechanism, \"power\": var_group_power, \"control\": var_group_control, \"external\": var_group_external, \"recorder\": var_group_recorder, \"unclassified\": var_group_unclassified}\n",
    "for group_name, var_group in var_groups_dict.items():\n",
    "    group_lens_dict[group_name] = len(var_group)\n",
    "    print(f\"{group_name}: {len(var_group)}\")\n",
    "print(f\"\\n{sum(group_lens_dict.values())} variables in total\")\n",
    "\n",
    "# 查找给定总序数对应的变量名称\n",
    "def find_var_name(idx, var_dict):\n",
    "    count = 0\n",
    "    group_lens_dict = {}\n",
    "    for group_name, var_group in var_dict.items():\n",
    "        group_lens_dict[group_name] = len(var_group)\n",
    "    for group_name, var_group in var_dict.items():\n",
    "        if count + group_lens_dict[group_name] > idx:\n",
    "            return group_name, var_group[idx - count]\n",
    "        else:\n",
    "            count += group_lens_dict[group_name]\n",
    "\n",
    "# 查找给定变量名称对应的总序数\n",
    "def find_var_idx(var_name, var_dict):\n",
    "    count = 0\n",
    "    for var_list in var_dict.values():\n",
    "        if var_name in var_list:\n",
    "            count += var_list.index(var_name)\n",
    "            return(count)\n",
    "        else:\n",
    "            count += len(var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算粗糙度矩阵\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置工作目录\n",
    "download_folder_name = 'Tail_652_1'\n",
    "\n",
    "# 设置结果存储目录\n",
    "cluster_save_path = '../result/variable_cluster/rough'\n",
    "if not os.path.exists(cluster_save_path):\n",
    "    os.mkdir(cluster_save_path)\n",
    "\n",
    "def getMetricsArray(folder_path, mat_name):\n",
    "# for mat_name in os.listdir(os.path.join(download_save_path, download_folder_name)):\n",
    "# for mat_name in [os.listdir(os.path.join(download_save_path, download_folder_name))[0]]:\n",
    "    # 载入mat文件\n",
    "    mat = loadmat(os.path.join(folder_path, mat_name))\n",
    "    # 将mat文件整理成(163, )的array\n",
    "    wshr_data = mat[\"WSHR\"][0][0][0]\n",
    "    sampling_data_array = []\n",
    "    for var_list in var_groups_dict.values():\n",
    "        for var_name in var_list:\n",
    "            var_data, var_rate = mat[var_name][0][0][0], mat[var_name][0][0][1][0][0]\n",
    "            # 对每个变量按照rate进行下采样或过采样，对长为n+1的数据，抓取前n个全变量为输入，后n个有缺变量为输出\n",
    "            if var_rate == 1:\n",
    "                sampling_data = var_data\n",
    "            else: # 进行重采样\n",
    "                sampling_data = [var_data[i] for i in np.linspace(0, len(var_data)- 1, len(wshr_data), dtype=int)]\n",
    "            # 将采样数据进行min_max归一化\n",
    "            if (np.max(sampling_data) - np.min(sampling_data)) > 1e-5:\n",
    "                sampling_data = (sampling_data - np.min(sampling_data)) / (np.max(sampling_data) - np.min(sampling_data))\n",
    "            else:\n",
    "                sampling_data = sampling_data\n",
    "            # print(np.max(sampling_data), np.min(sampling_data))\n",
    "            sampling_data_array.append(sampling_data)\n",
    "    summary_data_array = np.squeeze(np.array(sampling_data_array))\n",
    "    \n",
    "    # 计算粗糙度\n",
    "    roughness_matrix = summary_data_array[:, 1:] - summary_data_array[:, :-1]\n",
    "    # print(roughness_matrix.shape)\n",
    "    # plt.figure(figsize=(50, 5))\n",
    "    # plt.boxplot(roughness_matrix.T)\n",
    "    # plt.show()\n",
    "    # roughness_matrix_list.append(roughness_matrix)\n",
    "\n",
    "    # 将粗糙度和光滑度的标准差tuple作为聚类metrics\n",
    "    # print(np.std(summary_data_array, axis=1).shape)\n",
    "    # print(np.std(roughness_matrix, axis=1).shape)\n",
    "    metrics_array = np.squeeze(np.array([np.std(sampling_data_array, axis=1).reshape(-1, 1), np.std(roughness_matrix, axis=1).reshape(-1, 1)]).T)\n",
    "    # metrics_list.append([np.max(roughness_matrix_list[i], axis=1), np.max(smoothness_matrix_list[i], axis=1), \\\n",
    "    #                      np.std(roughness_matrix_list[i], axis=1), np.std(smoothness_matrix_list[i], axis=1)])\n",
    "    # metrics_list.append([[min(len(Counter(roughness_matrix_list[i][j])), discrete_value) for j in range(163)], [min(len(Counter(smoothness_matrix_list[i][j])), discrete_value) for j in range(163)], \\\n",
    "    #                      np.std(roughness_matrix_list[i], axis=1), np.std(smoothness_matrix_list[i], axis=1)])\n",
    "\n",
    "    # break\n",
    "    return summary_data_array, roughness_matrix, metrics_array\n",
    "\n",
    "# # 存储粗糙度和光滑度list\n",
    "# roughness_matrix_array = np.array([matrix.ravel() for matrix in roughness_matrix_list])\n",
    "# smoothness_matrix_array = np.array([matrix.ravel() for matrix in smoothness_matrix_list])\n",
    "# np.save(os.path.join(cluster_save_path, \"roughness_matrix_array.npy\"), roughness_matrix_array)\n",
    "# np.save(os.path.join(cluster_save_path, \"smoothness_matrix_array.npy\"), smoothness_matrix_array)\n",
    "\n",
    "\n",
    "# 进行K-means聚类\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "# from collections import Counter\n",
    "\n",
    "plt_save_path = os.path.join(cluster_save_path, \"variable_figures\")\n",
    "\n",
    "# print(metrics_array.shape)\n",
    "# np.save(os.path.join(cluster_save_path, \"metrics_array.npy\"), metrics_array)\n",
    "# metrics_array = np.load(os.path.join(cluster_save_path, \"metrics_array.npy\"))\n",
    "\n",
    "# K-means聚类\n",
    "for mat_name in os.listdir(work_folder_path):\n",
    "    plt_mat_path = os.path.join(plt_save_path, mat_name)\n",
    "    os.makedirs(plt_mat_path, exist_ok=True)\n",
    "\n",
    "    summary_data_array, roughness_matrix, metrics_array = getMetricsArray(work_folder_path, mat_name)\n",
    "    \n",
    "    # 计算最好的聚类类别数\n",
    "    clustering_metrics_list = [[], [], []]\n",
    "    cluster_label_list = []\n",
    "    K_start, K_end = 5, 10\n",
    "    for K in range(K_start, K_end+1):\n",
    "        cluster_labels = KMeans(n_clusters=K, random_state=9, n_init='auto').fit_predict(metrics_array)\n",
    "        cluster_label_list.append(cluster_labels)\n",
    "        # np.save(os.path.join(cluster_save_path, \"cluster_labels.npy\"), cluster_labels)\n",
    "        # clustering_metrics_list[0].append(metrics.calinski_harabasz_score(metrics_array, cluster_labels)/10) # 越大越好\n",
    "        clustering_metrics_list[0].append(0)\n",
    "        clustering_metrics_list[1].append(metrics.silhouette_score(metrics_array, cluster_labels)-0.5) # 越大越好\n",
    "        clustering_metrics_list[2].append(0.5-metrics.davies_bouldin_score(metrics_array, cluster_labels)) # 越小越好\n",
    "    clustering_metrics_sum_list = np.sum(clustering_metrics_list, axis=0)\n",
    "    # print(clustering_metrics_sum_list)\n",
    "    K = np.where(clustering_metrics_sum_list == np.max(clustering_metrics_sum_list))[0][0] + K_start\n",
    "    cluster_labels = cluster_label_list[K - K_start]\n",
    "\n",
    "    # 输出聚类中心\n",
    "    cluster_centers = []\n",
    "    for k in range(K):\n",
    "        center = np.mean(metrics_array[cluster_labels == k], axis=0)\n",
    "        cluster_centers.append([round(center[0], 2), round(center[1], 2)])\n",
    "    # print(cluster_centers)\n",
    "\n",
    "    # 重新排列roughness的原始数据\n",
    "    roughness_matrix_clu = []\n",
    "    for k in range(K):\n",
    "        roughness_matrix_clu.extend(roughness_matrix[cluster_labels == k])\n",
    "    roughness_matrix_clu = np.array(roughness_matrix_clu)\n",
    "\n",
    "    # 按类别打印roughness和smoothness的箱线图\n",
    "    plt.figure(figsize=(50, 5))\n",
    "    plt.boxplot(roughness_matrix.T)\n",
    "    plt.title(f\"Roughness_origin\")\n",
    "    plt.xlabel(f\"Variables\")\n",
    "    plt.ylabel(f\"Roughness\")\n",
    "    plt.savefig(os.path.join(plt_mat_path, \"Roughness_origin.png\"))\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(50, 5))\n",
    "    plt.boxplot(roughness_matrix_clu.T)\n",
    "    plt.title(f\"Roughness_clustered\")\n",
    "    plt.xlabel(f\"Variables\")\n",
    "    plt.ylabel(f\"Roughness\")\n",
    "    plt.savefig(os.path.join(plt_mat_path, \"Roughness_clustered.png\"))\n",
    "    plt.show()\n",
    "\n",
    "    # 可视化\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(metrics_array[:,0], metrics_array[:,1], c=cluster_labels)\n",
    "    # plt.gca().legend(labels = [f\"Cluster {k}\" for k in range(K)], loc='best')\n",
    "    plt.title(f\"Clustering {K} Groups\")\n",
    "    plt.xlabel(f\"Sampling Std\")\n",
    "    plt.ylabel(f\"Roughness\")\n",
    "    plt.savefig(os.path.join(plt_mat_path, \"Clustering_Groups.png\"))\n",
    "    plt.show()\n",
    "\n",
    "    # 按照聚类标签输出各类的图片\n",
    "    for k in range(K):\n",
    "        cluster_plt_save_path = os.path.join(plt_mat_path, f\"cluster {k+1} {cluster_centers[k]}\")\n",
    "        os.makedirs(cluster_plt_save_path, exist_ok=True)\n",
    "        for idx in np.where(cluster_labels == k)[0]:\n",
    "            sampling_data = summary_data_array[idx]\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.plot(range(1, len(sampling_data)+1), sampling_data)\n",
    "            plt.title(f\"Cluster {k}: {find_var_name(idx, var_groups_dict)}\")\n",
    "            plt.savefig(os.path.join(cluster_plt_save_path, f\"{find_var_name(idx, var_groups_dict)}.png\"))\n",
    "            plt.show()\n",
    "        #     break\n",
    "        # break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算粗糙度和光滑度矩阵\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置工作目录\n",
    "download_folder_name = 'Tail_652_1'\n",
    "\n",
    "# 设置结果存储目录\n",
    "cluster_save_path = '../result/variable_cluster/rough&smooth'\n",
    "if not os.path.exists(cluster_save_path):\n",
    "    os.mkdir(cluster_save_path)\n",
    "\n",
    "# 初始化结果存储array\n",
    "roughness_matrix_list = []\n",
    "smoothness_matrix_list = []\n",
    "\n",
    "def getMetricsArray(folder_path, mat_name):\n",
    "# for mat_name in os.listdir(os.path.join(download_save_path, download_folder_name)):\n",
    "# for mat_name in [os.listdir(os.path.join(download_save_path, download_folder_name))[0]]:\n",
    "    # 载入mat文件\n",
    "    mat = loadmat(os.path.join(folder_path, mat_name))\n",
    "    # 将mat文件整理成(163, )的array\n",
    "    wshr_data = mat[\"WSHR\"][0][0][0]\n",
    "    sampling_data_array = []\n",
    "    for var_list in var_groups_dict.values():\n",
    "        for var_name in var_list:\n",
    "            var_data, var_rate = mat[var_name][0][0][0], mat[var_name][0][0][1][0][0]\n",
    "            # 对每个变量按照rate进行下采样或过采样，对长为n+1的数据，抓取前n个全变量为输入，后n个有缺变量为输出\n",
    "            if var_rate == 1:\n",
    "                sampling_data = var_data\n",
    "            elif var_rate > 1: # 进行下采样\n",
    "                sampling_data = random.sample(var_data.tolist(), k=len(wshr_data))\n",
    "            else:\n",
    "                sampling_data = random.choices(var_data, k=len(wshr_data))\n",
    "            # 将采样数据进行min_max归一化\n",
    "            if (np.max(sampling_data) - np.min(sampling_data)) > 1e-5:\n",
    "                sampling_data = (sampling_data - np.min(sampling_data)) / (np.max(sampling_data) - np.min(sampling_data))\n",
    "            else:\n",
    "                sampling_data = sampling_data\n",
    "            # print(np.max(sampling_data), np.min(sampling_data))\n",
    "            sampling_data_array.append(sampling_data)\n",
    "    summary_data_array = np.squeeze(np.array(sampling_data_array))\n",
    "    \n",
    "    # 计算粗糙度\n",
    "    roughness_matrix = summary_data_array[:, 1:] - summary_data_array[:, :-1]\n",
    "    # print(roughness_matrix.shape)\n",
    "    # plt.figure(figsize=(50, 5))\n",
    "    # plt.boxplot(roughness_matrix.T)\n",
    "    # plt.show()\n",
    "    # roughness_matrix_list.append(roughness_matrix)\n",
    "\n",
    "    # 计算光滑程度\n",
    "    smoothness_matrix = (roughness_matrix[:, 1:] - roughness_matrix[:, :-1]) / 2\n",
    "    # print(smoothness_matrix.shape)\n",
    "    # plt.figure(figsize=(50, 5))\n",
    "    # plt.boxplot(smoothness_matrix.T)\n",
    "    # plt.show()\n",
    "    # smoothness_matrix_list.append(smoothness_matrix)\n",
    "\n",
    "    # 将粗糙度和光滑度的标准差tuple作为聚类metrics\n",
    "    metrics_array = np.array([np.std(roughness_matrix, axis=1), np.std(smoothness_matrix, axis=1)]).T\n",
    "    # metrics_list.append([np.max(roughness_matrix_list[i], axis=1), np.max(smoothness_matrix_list[i], axis=1), \\\n",
    "    #                      np.std(roughness_matrix_list[i], axis=1), np.std(smoothness_matrix_list[i], axis=1)])\n",
    "    # metrics_list.append([[min(len(Counter(roughness_matrix_list[i][j])), discrete_value) for j in range(163)], [min(len(Counter(smoothness_matrix_list[i][j])), discrete_value) for j in range(163)], \\\n",
    "    #                      np.std(roughness_matrix_list[i], axis=1), np.std(smoothness_matrix_list[i], axis=1)])\n",
    "\n",
    "    # print(summary_data_array.shape)\n",
    "    # print(roughness_matrix.shape)\n",
    "    # print(smoothness_matrix.shape)\n",
    "\n",
    "    # break\n",
    "    return summary_data_array, roughness_matrix, smoothness_matrix, metrics_array\n",
    "\n",
    "# # 存储粗糙度和光滑度list\n",
    "# roughness_matrix_array = np.array([matrix.ravel() for matrix in roughness_matrix_list])\n",
    "# smoothness_matrix_array = np.array([matrix.ravel() for matrix in smoothness_matrix_list])\n",
    "# np.save(os.path.join(cluster_save_path, \"roughness_matrix_array.npy\"), roughness_matrix_array)\n",
    "# np.save(os.path.join(cluster_save_path, \"smoothness_matrix_array.npy\"), smoothness_matrix_array)\n",
    "\n",
    "\n",
    "# 进行K-means聚类\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "# from collections import Counter\n",
    "\n",
    "plt_save_path = os.path.join(cluster_save_path, \"variable_figures\")\n",
    "\n",
    "# print(metrics_array.shape)\n",
    "# np.save(os.path.join(cluster_save_path, \"metrics_array.npy\"), metrics_array)\n",
    "# metrics_array = np.load(os.path.join(cluster_save_path, \"metrics_array.npy\"))\n",
    "\n",
    "# K-means聚类\n",
    "for mat_name in os.listdir(work_folder_path):\n",
    "    plt_mat_path = os.path.join(plt_save_path, mat_name)\n",
    "    os.makedirs(plt_mat_path, exist_ok=True)\n",
    "\n",
    "    summary_data_array, smoothness_matrix, roughness_matrix, metrics_array = getMetricsArray(work_folder_path, mat_name)\n",
    "    \n",
    "    # 计算最好的聚类类别数\n",
    "    clustering_metrics_list = [[], [], []]\n",
    "    cluster_label_list = []\n",
    "    K_start, K_end = 5, 10\n",
    "    for K in range(K_start, K_end+1):\n",
    "        cluster_labels = KMeans(n_clusters=K, random_state=9, n_init='auto').fit_predict(metrics_array)\n",
    "        cluster_label_list.append(cluster_labels)\n",
    "        # np.save(os.path.join(cluster_save_path, \"cluster_labels.npy\"), cluster_labels)\n",
    "        # clustering_metrics_list[0].append(metrics.calinski_harabasz_score(metrics_array, cluster_labels)/10) # 越大越好\n",
    "        clustering_metrics_list[0].append(0)\n",
    "        clustering_metrics_list[1].append(metrics.silhouette_score(metrics_array, cluster_labels)-0.5) # 越大越好\n",
    "        clustering_metrics_list[2].append(0.5-metrics.davies_bouldin_score(metrics_array, cluster_labels)) # 越小越好\n",
    "    clustering_metrics_sum_list = np.sum(clustering_metrics_list, axis=0)\n",
    "    # print(clustering_metrics_sum_list)\n",
    "    K = np.where(clustering_metrics_sum_list == np.max(clustering_metrics_sum_list))[0][0] + K_start\n",
    "    cluster_labels = cluster_label_list[K - K_start]\n",
    "\n",
    "    # 输出聚类中心\n",
    "    cluster_centers = []\n",
    "    for k in range(K):\n",
    "        center = np.mean(metrics_array[cluster_labels == k], axis=0)\n",
    "        cluster_centers.append([round(center[0], 2), round(center[1], 2)])\n",
    "    # print(cluster_centers)\n",
    "\n",
    "    # 重新排列roughness和smoothness的原始数据\n",
    "    roughness_matrix_clu, smoothness_matrix_clu = [], []\n",
    "    for k in range(K):\n",
    "        roughness_matrix_clu.extend(roughness_matrix[cluster_labels == k])\n",
    "        smoothness_matrix_clu.extend(smoothness_matrix[cluster_labels == k])\n",
    "    roughness_matrix_clu = np.array(roughness_matrix_clu)\n",
    "    smoothness_matrix_clu = np.array(smoothness_matrix_clu)\n",
    "\n",
    "    # 按类别打印roughness和smoothness的箱线图\n",
    "    plt.figure(figsize=(50, 5))\n",
    "    plt.boxplot(roughness_matrix.T)\n",
    "    plt.title(f\"Roughness_origin\")\n",
    "    plt.xlabel(f\"Variables\")\n",
    "    plt.ylabel(f\"Roughness\")\n",
    "    plt.savefig(os.path.join(plt_mat_path, \"Roughness_origin.png\"))\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(50, 5))\n",
    "    plt.boxplot(smoothness_matrix.T)\n",
    "    plt.title(f\"Smoothness_origin\")\n",
    "    plt.xlabel(f\"Variables\")\n",
    "    plt.ylabel(f\"Smoothness\")\n",
    "    plt.savefig(os.path.join(plt_mat_path, \"Smoothness_origin.png\"))\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(50, 5))\n",
    "    plt.boxplot(roughness_matrix_clu.T)\n",
    "    plt.title(f\"Roughness_clustered\")\n",
    "    plt.xlabel(f\"Variables\")\n",
    "    plt.ylabel(f\"Roughness\")\n",
    "    plt.savefig(os.path.join(plt_mat_path, \"Roughness_clustered.png\"))\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(50, 5))\n",
    "    plt.boxplot(smoothness_matrix_clu.T)\n",
    "    plt.title(f\"Smoothness_clustered\")\n",
    "    plt.xlabel(f\"Variables\")\n",
    "    plt.ylabel(f\"Smoothness\")\n",
    "    plt.savefig(os.path.join(plt_mat_path, \"Smoothness_clustered.png\"))\n",
    "    plt.show()\n",
    "\n",
    "    # # 输出对应变量组\n",
    "    # for k in range(K):\n",
    "    #     cluster_idx = np.where(cluster_labels == k)[0]\n",
    "    #     cluster_var_name_dict = {find_var_name(idx, var_groups_dict): {'r': round(metrics_array[idx][0], 2), 's': round(metrics_array[idx][1], 2) } for idx in cluster_idx}\n",
    "    #     if len(cluster_var_name_dict) < 163:\n",
    "    #         print(f\"{len(cluster_var_name_dict)}:{cluster_var_name_dict.keys()}\")\n",
    "\n",
    "    # 可视化\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(metrics_array[:,0], metrics_array[:,1], c=cluster_labels)\n",
    "    # plt.gca().legend(labels = [f\"Cluster {k}\" for k in range(K)], loc='best')\n",
    "    plt.title(f\"Clustering {K} Groups\")\n",
    "    plt.xlabel(f\"Roughness\")\n",
    "    plt.ylabel(f\"Smoothness\")\n",
    "    plt.savefig(os.path.join(plt_mat_path, \"Clustering_Groups.png\"))\n",
    "    plt.show()\n",
    "\n",
    "    # 按照聚类标签输出各类的图片\n",
    "    for k in range(K):\n",
    "        cluster_plt_save_path = os.path.join(plt_mat_path, f\"cluster {k+1} {cluster_centers[k]}\")\n",
    "        os.makedirs(cluster_plt_save_path, exist_ok=True)\n",
    "        for idx in np.where(cluster_labels == k)[0]:\n",
    "            sampling_data = summary_data_array[idx]\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.plot(range(1, len(sampling_data)+1), sampling_data)\n",
    "            plt.title(f\"Cluster {k}: {find_var_name(idx, var_groups_dict)}\")\n",
    "            plt.savefig(os.path.join(cluster_plt_save_path, f\"{find_var_name(idx, var_groups_dict)}.png\"))\n",
    "            plt.show()\n",
    "        #     break\n",
    "        # break\n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
