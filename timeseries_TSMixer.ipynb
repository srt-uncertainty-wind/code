{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDataLoader\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Revised base on https://zhuanlan.zhihu.com/p/667766822\n",
    "'''\n",
    "\n",
    "# 创建DataLoader进行数据集转换\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "    device = 'cuda'\n",
    "\n",
    "class DataLoader:\n",
    "\n",
    "    def __init__(self, batch_size, seq_len, pred_len):\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.target_slice = slice(0, None)\n",
    "\n",
    "        self._read_data()\n",
    "\n",
    "    # 读取数据\n",
    "    def _read_data(self):\n",
    "        '''\n",
    "        扩展数据以缩短模型的训练时间至关重要；\n",
    "        将缩放器安装在训练集上只是为了避免验证和测试集中的数据泄漏\n",
    "        '''\n",
    "\n",
    "        filepath = ('../Dataset/Simulate_Data/set_1/File_indexed.xlsx')\n",
    "\n",
    "        df_raw = pd.read_excel(filepath)\n",
    "        df = df_raw.set_index('TIME')\n",
    "\n",
    "        # split train/valid/test\n",
    "        n = len(df)\n",
    "        train_end = int(n * 0.7)\n",
    "        val_end = n - int(n * 0.2)\n",
    "        test_end = n\n",
    "\n",
    "        train_df = df[:train_end]\n",
    "        val_df = df[train_end - self.seq_len : val_end]\n",
    "        test_df = df[val_end - self.seq_len : test_end]\n",
    "\n",
    "        # standardize by training set\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(train_df.values)\n",
    "\n",
    "        def scale_df(df, scaler):\n",
    "            data = scaler.transform(df.values)\n",
    "            return pd.DataFrame(data, index=df.index, columns=df.columns)\n",
    "\n",
    "        self.train_df = scale_df(train_df, self.scaler)\n",
    "        self.val_df = scale_df(val_df, self.scaler)\n",
    "        self.test_df = scale_df(test_df, self.scaler)\n",
    "        self.n_feature = self.train_df.shape[-1]\n",
    "\n",
    "    # 将数据窗口分割为输入和标签\n",
    "    def _split_window(self, data):\n",
    "        inputs = data[:, : self.seq_len, :]\n",
    "        labels = data[:, self.seq_len :, self.target_slice]\n",
    "\n",
    "        inputs.set_shape([None, self.seq_len, None])\n",
    "        labels.set_shape([None, self.pred_len, None])\n",
    "        return inputs, labels\n",
    "\n",
    "    def _make_dataset(self, data, shuffle=True):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=(self.seq_len + self.pred_len),\n",
    "            sequence_stride=1,\n",
    "            shuffle=shuffle,\n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "        ds = ds.map(self._split_window)\n",
    "        return ds\n",
    "\n",
    "    # DataLoader通过对预测进行逆变换，生成训练集、验证集和测试集\n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)\n",
    "\n",
    "    def get_train(self, shuffle=True):\n",
    "        return self._make_dataset(self.train_df, shuffle=shuffle)\n",
    "\n",
    "    def get_val(self):\n",
    "        return self._make_dataset(self.val_df, shuffle=False)\n",
    "\n",
    "    def get_test(self):\n",
    "        return self._make_dataset(self.test_df, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建TSMixer网络\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def res_block(inputs, norm_type, activation, dropout, ff_dim):\n",
    "    \n",
    "    norm = layers.BatchNormalization\n",
    "\n",
    "    # Time mixing\n",
    "    '''\n",
    "    混合器层，它包括：\n",
    "        批量归一化\n",
    "        转置矩阵\n",
    "        通过 ReLu 激活馈送到全连接层\n",
    "        再次转置\n",
    "        漏失层\n",
    "        并在最后添加残差\n",
    "    '''\n",
    "    x = norm(axis=[-2, -1])(inputs)\n",
    "    x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Channel, Input Length]\n",
    "    x = layers.Dense(x.shape[-1], activation='relu')(x)\n",
    "    x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Input Length, Channel]\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feature mixing\n",
    "    '''\n",
    "    特征混合部分，其中：\n",
    "        批量归一化\n",
    "        致密层\n",
    "        一个dropout层\n",
    "        另一个致密层\n",
    "        另一个dropout层\n",
    "        并添加残差以进行残差连接\n",
    "    '''\n",
    "    x = norm(axis=[-2, -1])(res)\n",
    "    x = layers.Dense(ff_dim, activation='relu')(x)  # [Batch, Input Length, FF_Dim]\n",
    "    x = layers.Dropout(0.7)(x)\n",
    "    x = layers.Dense(inputs.shape[-1])(x)  # [Batch, Input Length, Channel]\n",
    "    x = layers.Dropout(0.7)(x)\n",
    "    return x + res\n",
    "\n",
    "def build_model(\n",
    "    input_shape,\n",
    "    pred_len,\n",
    "    n_block,\n",
    "    ff_dim,\n",
    "    target_slice,\n",
    "):\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = inputs  # [Batch, Input Length, Channel]\n",
    "    for _ in range(n_block):\n",
    "        x = res_block(x, norm_type, activation, dropout, ff_dim)\n",
    "\n",
    "    if target_slice:\n",
    "        x = x[:, :, target_slice]\n",
    "\n",
    "  # Temporal projection\n",
    "    '''\n",
    "    时间投影步骤：\n",
    "        转置\n",
    "        穿过致密层\n",
    "        最终转置\n",
    "    '''\n",
    "    x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Channel, Input Length]\n",
    "    x = layers.Dense(pred_len)(x)  # [Batch, Channel, Output Length]\n",
    "    outputs = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Output Length, Channel])\n",
    "\n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_core.keras.preprocessing' has no attribute 'timeseries_dataset_from_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_43512\\3974373114.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdata_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m96\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mval_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_43512\\3428832544.py\u001b[0m in \u001b[0;36mget_train\u001b[1;34m(self, shuffle)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_43512\\3428832544.py\u001b[0m in \u001b[0;36m_make_dataset\u001b[1;34m(self, data, shuffle)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mtargets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow_core.keras.preprocessing' has no attribute 'timeseries_dataset_from_array'"
     ]
    }
   ],
   "source": [
    "# 初始化DataLoader来读取数据集并创建训练集、验证集和测试集\n",
    "data_loader = DataLoader(batch_size=32, seq_len=512, pred_len=96)\n",
    "\n",
    "train_data = data_loader.get_train()\n",
    "val_data = data_loader.get_val()\n",
    "test_data = data_loader.get_test()\n",
    "\n",
    "# 初始化SMixer模型\n",
    "model = build_model(\n",
    "    input_shape=(512, data_loader.n_feature),\n",
    "    pred_len=96,\n",
    "    n_block=8,\n",
    "    ff_dim=64,\n",
    "    target_slice=data_loader.target_slice\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "'''\n",
    "使用学习率为 1e-4 的 Adam 优化器;\n",
    "实施检查点来保存最佳模型;\n",
    "在连续三个时期没有改进的情况下提前停止以停止训练。\n",
    "'''\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "model.compile(optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='tsmixer_checkpoints/',\n",
    "    vebose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs= 30,\n",
    "    validation_data=val_data,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback]\n",
    ")\n",
    "\n",
    "# 在模型训练完毕后加载检查点回调保存的最佳模型\n",
    "best_epoch = np.argmin(history.history['val_loss'])\n",
    "\n",
    "model.load_weights(\"tsmixer_checkpoints/\")\n",
    "\n",
    "# 访问96个时间步长的最后一个窗口的预测（已按比例缩放）\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "scaled_preds = predictions[-1,:,:]\n",
    "\n",
    "# 将缩放和逆变换的预测存储在 DataFrame 中，以评估性能并稍后绘制预测\n",
    "cols = ['HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT']\n",
    "\n",
    "scaled_preds_df = pd.DataFrame(scaled_preds)\n",
    "scaled_preds_df.columns = cols\n",
    "\n",
    "preds = data_loader.inverse_transform(scaled_preds)\n",
    "\n",
    "preds_df = pd.DataFrame(preds)\n",
    "preds_df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化预测结果\n",
    "tsmixer_preds = preds\n",
    "\n",
    "cols_to_plot = ['HUFL', 'HULL', 'MUFL', 'MULL']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12,8))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    col = cols_to_plot[i]\n",
    "    \n",
    "    ax.plot(test_data['date'][-96:], test_data[col][-96:])\n",
    "    ax.plot(test_data['date'][-96:], tsmixer_preds[col], label='TSMixer', ls='--', color='green')\n",
    "    \n",
    "    ax.legend(loc='best')\n",
    "    ax.set_xlabel('Time steps')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.set_title(col)\n",
    "    \n",
    "plt.tight_layout()\n",
    "fig.autofmt_xdate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
