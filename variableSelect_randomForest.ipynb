{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "\n",
    "# 指定文件夹路径\n",
    "download_save_path = 'E:/Dataset/wind_shear/Data_Download'\n",
    "exception_save_path = '../Dataset/Exception_Data'\n",
    "plt_save_path = '../result/WSHR/figures'\n",
    "\n",
    "# 获取文件夹下的所有文件名称\n",
    "dowload_folder_names = [item for item in os.listdir(download_save_path) if os.path.isdir(os.path.join(download_save_path, item))]\n",
    "exception_folder_names = [item for item in os.listdir(exception_save_path) if os.path.isdir(os.path.join(exception_save_path, item))]\n",
    "instruction_folder_names = [\"@Instructions\"]\n",
    "\n",
    "# 生成所有文件夹路径\n",
    "dowload_folder_paths = [os.path.join(download_save_path, item) for item in dowload_folder_names]\n",
    "exception_folder_paths = [os.path.join(exception_save_path, item) for item in exception_folder_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mechanism: 38\n",
      "power: 47\n",
      "control: 37\n",
      "external: 15\n",
      "recorder: 7\n",
      "unclassified: 19\n",
      "\n",
      "163 variables in total\n"
     ]
    }
   ],
   "source": [
    "# give the preset classification of variables\n",
    "group_names_list = [\"mechanism\", \"power\", \"control\", \"external\", \"recorder\", \"unclassified\"]\n",
    "group_lens_dict = {}\n",
    "\n",
    "var_group_mechanism = [\"AIL_1\", \"AIL_2\", \"FLAP\", \"ELEV_1\", \"ELEV_2\", \"RUDD\", \"SPL_1\", \"SPL_2\", \"SPLG\", \"SPLY\", \"ABRK\", \"BPGR_1\", \"BPGR_2\", \"BPYR_1\", \"BPYR_2\", \"MSQT_1\", \"MSQT_2\", \"NSQT\", \"BLV\", \"CALT\", \"PACK\", \"WOW\", \n",
    "                       \"AOA1\", \"AOA2\", \"GLS\", \"PTCH\", \"ROLL\", \n",
    "                       \"TH\", \"MH\", \"TAS\", \"CASM\", \"GS\", \"IVV\",\n",
    "                       \"VRTG\", \"LATG\", \"LONG\", \"FPAC\", \"CTAC\"]\n",
    "var_group_power = [\"N2_1\", \"N2_2\", \"N2_3\", \"N2_4\",\n",
    "                   \"ECYC_1\", \"ECYC_2\", \"ECYC_3\", \"ECYC_4\", \"EHRS_1\", \"EHRS_2\", \"EHRS_3\", \"EHRS_4\", \"VIB_1\", \"VIB_2\", \"VIB_3\", \"VIB_4\", \"FADS\", \"HYDG\", \"HYDY\",\n",
    "                   \"N1_1\", \"N1_2\", \"N1_3\", \"N1_4\", \"N1T\", \"FF_1\", \"FF_2\", \"FF_3\", \"FF_4\", \"FQTY_1\", \"FQTY_2\", \"FQTY_3\", \"FQTY_4\", \"OIP_1\", \"OIP_2\", \"OIP_3\", \"OIP_4\", \"OIT_1\", \"OIT_2\", \"OIT_3\", \"OIT_4\", \"OIPL\", \"EGT_1\", \"EGT_2\", \"EGT_3\", \"EGT_4\",\n",
    "                   \"LGDN\", \"LGUP\"]\n",
    "var_group_control = [\"CRSS\", \"HDGS\", \"A_T\", \"APFD\", \"DFGS\", \"FGC3\", \"PUSH\", \"PTRM\", \"TCAS\",\n",
    "                     \"ILSF\", \"RUDP\", \"CCPC\", \"CCPF\", \"CWPC\", \"CWPF\", \"PLA_1\", \"PLA_2\", \"PLA_3\", \"PLA_4\",\n",
    "                     \"SNAP\", \"TMODE\", \"EAI\", \"TAI\", \"WAI_1\", \"WAI_2\", \n",
    "                     \"APUF\", \"FADF\", \"FIRE_1\", \"FIRE_2\", \"FIRE_3\", \"FIRE_4\", \"GPWS\", \"MW\", \"POVT\", \"SHKR\", \"SMOK\", \"TOCW\"]\n",
    "var_group_external = [\"ALT\", \"ALTR\", \"WS\", \"WD\", \"PI\", \"PS\", \"PT\", \"SAT\", \"TAT\",\n",
    "                      \"DA\", \"TRK\", \"TRKM\", \"LOC\", \"LATP\", \"LONP\"]\n",
    "var_group_recorder = [\"DWPT\", \"PH\", \n",
    "                     \"ACMT\", \"FRMC\", \"GMT_HOUR\", \"GMT_MINUTE\", \"GMT_SEC\"]\n",
    "var_group_unclassified = [\"ATEN\", \"EVNT\", \"HF1\", \"HF2\", \"VHF1\", \"VHF2\", \"VHF3\", \"LMOD\", \"VMODE\", \"MACH\", \"MNS\", \"MRK\", \"N1C\", \"N1CO\", \"SMKB\", \"VAR_1107\", \"VAR_2670\", \"VAR_5107\", \"VAR_6670\"]\n",
    "\n",
    "var_groups_dict = {\"mechanism\": var_group_mechanism, \"power\": var_group_power, \"control\": var_group_control, \"external\": var_group_external, \"recorder\": var_group_recorder, \"unclassified\": var_group_unclassified}\n",
    "for group_name, var_group in var_groups_dict.items():\n",
    "    group_lens_dict[group_name] = len(var_group)\n",
    "    print(f\"{group_name}: {len(var_group)}\")\n",
    "print(f\"\\n{sum(group_lens_dict.values())} variables in total\")\n",
    "\n",
    "# 给定数据不完整的变量列表\n",
    "invalid_var_dict = {'mechanism': ['FLAP', 'SPLG', 'SPLY', 'BPGR_1', 'BPGR_2', 'BPYR_1', 'BPYR_2', 'MSQT_1', 'MSQT_2', 'NSQT', 'BLV', 'CALT', 'PACK', 'WOW', 'AOA1', 'AOA2', 'GLS', 'PTCH', 'ROLL', 'TH', 'MH', 'TAS', 'CASM', 'GS', 'IVV', 'FPAC', 'CTAC'], \\\n",
    "                    'power': ['N2_1', 'N2_2', 'N2_3', 'N2_4', 'ECYC_1', 'ECYC_2', 'ECYC_3', 'ECYC_4', 'EHRS_1', 'EHRS_2', 'EHRS_3', 'EHRS_4', 'VIB_1', 'VIB_2', 'VIB_3', 'VIB_4', 'FADS', 'HYDG', 'HYDY', 'N1_1', 'N1_2', 'N1_3', 'N1_4', 'N1T', 'FF_1', 'FF_2', 'FF_3', 'FF_4', 'FQTY_1', 'FQTY_2', 'FQTY_3', 'FQTY_4', 'OIP_1', 'OIP_2', 'OIP_3', 'OIP_4', 'OIPL', 'EGT_1', 'EGT_2', 'EGT_3', 'EGT_4', 'LGDN', 'LGUP'], \\\n",
    "                        'control': ['CRSS', 'HDGS', 'A_T', 'APFD', 'DFGS', 'FGC3', 'PUSH', 'TCAS', 'RUDP', 'CCPC', 'CCPF', 'CWPC', 'CWPF', 'PLA_1', 'PLA_2', 'PLA_3', 'PLA_4', 'SNAP', 'TMODE', 'EAI', 'TAI', 'WAI_1', 'WAI_2', 'APUF', 'FADF', 'FIRE_1', 'FIRE_2', 'FIRE_3', 'FIRE_4', 'MW', 'POVT', 'SHKR', 'SMOK', 'TOCW'], \\\n",
    "                            'external': ['ALT', 'ALTR', 'WS', 'WD', 'PI', 'PS', 'PT', 'SAT', 'TAT', 'DA', 'TRK', 'TRKM', 'LOC', 'LATP'], \\\n",
    "                                'recorder': ['DWPT', 'PH', 'GMT_HOUR', 'GMT_MINUTE', 'GMT_SEC'], \\\n",
    "                                    'unclassified': ['ATEN', 'EVNT', 'HF1', 'HF2', 'VHF1', 'VHF2', 'VHF3', 'LMOD', 'VMODE', 'MACH', 'MNS', 'MRK', 'N1C', 'N1CO', 'SMKB']}\n",
    "\n",
    "valid_var_dict = {group_name: list(set(var_groups_dict[group_name]) - set(invalid_var_dict[group_name])) for group_name in var_groups_dict.keys()}\n",
    "\n",
    "# 查找给定总序数对应的变量名称\n",
    "def find_var_name(idx):\n",
    "    count = 0\n",
    "    for group_name, var_group in var_groups_dict.items():\n",
    "        if count + group_lens_dict[group_name] > idx:\n",
    "            return group_name, var_group[idx - count]\n",
    "        else:\n",
    "            count += group_lens_dict[group_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('control', 'PLA_1')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_var_name(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1252, 25)\n",
      "(1252, 1)\n"
     ]
    }
   ],
   "source": [
    "# 读取一个异常mat文件\n",
    "e_mat_path = os.path.join(exception_folder_paths[0], os.listdir(exception_folder_paths[0])[0])\n",
    "e_mat = loadmat(e_mat_path)\n",
    "\n",
    "# 初始化解释变量和响应变量的存储array\n",
    "explain_var_array, response_wshr_array = [], []\n",
    "\n",
    "# 分别读取自变量和WSHR因变量\n",
    "response_wshr_array = e_mat[\"WSHR\"][0][0][0]\n",
    "\n",
    "# for group_name, var_list in var_groups_dict.items():\n",
    "for group_name, var_list in valid_var_dict.items():\n",
    "    for var_name in var_list:\n",
    "        # 对每个变量按照rate进行下采样或过采样\n",
    "        var_data, var_rate = e_mat[var_name][0][0][0], e_mat[var_name][0][0][1][0][0]\n",
    "        if var_rate == 1:\n",
    "            explain_var_array.append(var_data)\n",
    "        elif var_rate > 1: # 进行下采样\n",
    "            # print(len(var_data.tolist()))\n",
    "            explain_var_array.append(random.sample(var_data.tolist(), k=len(response_wshr_array)))\n",
    "        else:\n",
    "            explain_var_array.append(random.choices(var_data, k=len(response_wshr_array)))\n",
    "\n",
    "explain_var_array = np.squeeze(np.array(explain_var_array)).T\n",
    "response_wshr_array = np.array(response_wshr_array)\n",
    "\n",
    "print(explain_var_array.shape)\n",
    "print(response_wshr_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 Features:\n",
      "1. Feature 2: ('mechanism', 'FLAP') (0.18728756381768843)\n",
      "2. Feature 9: ('mechanism', 'SPLY') (0.17378979969603303)\n",
      "3. Feature 6: ('mechanism', 'SPL_1') (0.08539396297892134)\n",
      "4. Feature 19: ('mechanism', 'CALT') (0.06690690059225032)\n",
      "5. Feature 8: ('mechanism', 'SPLG') (0.06442082556898619)\n",
      "6. Feature 4: ('mechanism', 'ELEV_2') (0.0644096725703083)\n",
      "7. Feature 14: ('mechanism', 'BPYR_2') (0.054608354593199175)\n",
      "8. Feature 0: ('mechanism', 'AIL_1') (0.054523932066631885)\n",
      "9. Feature 7: ('mechanism', 'SPL_2') (0.04962075887550051)\n",
      "10. Feature 1: ('mechanism', 'AIL_2') (0.04811360269031083)\n",
      "11. Feature 20: ('mechanism', 'PACK') (0.03734953286296099)\n",
      "12. Feature 3: ('mechanism', 'ELEV_1') (0.027890569266937042)\n",
      "13. Feature 15: ('mechanism', 'MSQT_1') (0.02664358505820865)\n",
      "14. Feature 5: ('mechanism', 'RUDD') (0.025704414563157328)\n",
      "15. Feature 12: ('mechanism', 'BPGR_2') (0.013797748871025466)\n",
      "16. Feature 11: ('mechanism', 'BPGR_1') (0.010469708847113741)\n",
      "17. Feature 13: ('mechanism', 'BPYR_1') (0.009069067080766895)\n",
      "18. Feature 10: ('mechanism', 'ABRK') (0.0)\n",
      "19. Feature 23: ('mechanism', 'AOA2') (0.0)\n",
      "20. Feature 16: ('mechanism', 'MSQT_2') (0.0)\n",
      "21. Feature 17: ('mechanism', 'NSQT') (0.0)\n",
      "22. Feature 18: ('mechanism', 'BLV') (0.0)\n",
      "23. Feature 21: ('mechanism', 'WOW') (0.0)\n",
      "24. Feature 22: ('mechanism', 'AOA1') (0.0)\n",
      "25. Feature 24: ('mechanism', 'GLS') (0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86108\\AppData\\Local\\Temp\\ipykernel_148304\\3828022564.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(explain_var_array, response_wshr_array)\n"
     ]
    }
   ],
   "source": [
    "# 创建随机森林分类器\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 拟合模型\n",
    "rf.fit(explain_var_array, response_wshr_array)\n",
    "\n",
    "# 获取特征重要性并排序输出\n",
    "feature_importances = rf.feature_importances_\n",
    "importances_indices = np.argsort(feature_importances)[::-1]\n",
    "top_k = explain_var_array.shape[1]  # 选择前 k 个重要性最高的特征\n",
    "feature_names = [f\"Feature {i}: {find_var_name(i)}\" for i in range(explain_var_array.shape[1])]\n",
    "\n",
    "print(\"Top\", top_k, \"Features:\")\n",
    "for i in range(top_k):\n",
    "    print(f\"{i+1}. {feature_names[importances_indices[i]]} ({feature_importances[importances_indices[i]]})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
